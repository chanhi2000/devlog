{
  "channel": {
    "id": "kafa46",
    "name": "소프트웨어 꼰대 강의",
    "profile": "https://yt3.googleusercontent.com/LxyfgAzvUqkaV_Q3mxqj16D4eKb-TO1_IYYoNuVLe3ZxJqCJlmSjbdldblIWP0II88w1URDL0A=s176-c-k-c0x00ffffff-no-rj",
    "banner": ""
  },
  "videos": [
    { "id": "G4SVV7bppyg", "title": "[OpenAI Whisper CS-based File ASR]_03. 프런트 구현 - base.html 및 main.html 코딩" },
    { "id": "mSwujzcZ__A", "title": "[OpenAI Whisper CS-based File ASR]_02. 프로젝트 구조(폴더) 잡기, , 기본 설정파일 코딩" },
    { "id": "IM-Ano8Yfdc", "title": "[OpenAI Whisper CS-based File ASR]_05. 음성파일 첨부를 위한 프런트엔드(asr_file.html) 구현" },
    { "id": "wAw7TcEFpGw", "title": "[OpenAI Whisper CS-based File ASR]_04. 서버 - 일부 views 구현, 서버 구동, base.html 업데이트" },
    { "id": "PgoHzI1TNlA", "title": "[OpenAI Whisper CS-based File ASR]_06. JavaScript 이용하여 멀티 파일 첨부 구현하고, 업로드 파일 보안 적용하기" },
    { "id": "Zz5U4xltx_c", "title": "[OpenAI Whisper CS-based File ASR]_08. 음성 파일을 서버로 전송하기 위한 프런트(JavaScript) 및 서버(upload function) 구현" },
    { "id": "6ZMVdTqzSbA", "title": "[OpenAI Whisper CS-based File ASR]_07. ASR 처리를 위한  클라이언트 - 서버 메시지 교환 로직의 이해" },
    { "id": "uXG0ht9OdDw", "title": "[OpenAI Whisper CS-based File ASR]_09. 클라이언트는 음성 파일을 서버로 전송, 서버는 전송 받은 파일을 저장하는 기능 구현" },
    { "id": "stBpJ4OrPcE", "title": "[OpenAI Whisper CS-based File ASR]_11. (코딩 마무리) 서버는 AI 엔진으로 텍스트 변환, 클라이언트는 최종 텍스트를 시현하는 기능 구현" },
    { "id": "VFiIujieAIc", "title": "[OpenAI Whisper CS-based File ASR]_10. 서버는 음성 파일을 처리하여 클라이언트로 보내고, 클라이언트는 데이터를 받아 페이지를 업데이트 하는 기능 구현" },
    { "id": "df_dGc5SqPo", "title": "[OpenAI Whisper CS-based File ASR]_12. Adjourning! 미니 프로젝트 마무리 인사" },
    { "id": "Q7SqTAH0pHk", "title": "[전이학습+딥러닝 서비스]_01. orientation" },
    { "id": "pstczQsOVSU", "title": "[전이학습+딥러닝 서비스]_03. 음성파일 변환 ( .pcm 을 .wav 파일로 변환)" },
    { "id": "tqqJbk_JK8k", "title": "[전이학습+딥러닝 서비스]_02. Dataset Acquisition (데이터 확보)" },
    { "id": "uumj5-A5LTI", "title": "[전이학습+딥러닝 서비스]_06. 큰 학습 데이터셋을 작은 그룹으로 나누기" },
    { "id": "ruLlrIzZG6Q", "title": "[전이학습+딥러닝 서비스]_05. 데이터셋 텍스트 파일 인코딩을 utf-8로 통일" },
    { "id": "reE3YscH34c", "title": "[전이학습+딥러닝 서비스]_04. Argparse를 이용한 audio 처리를 위한 하부 명령어 (sub-command) 등록 및 터미널 arguments 등록" },
    { "id": "1jtU6p4BSnE", "title": "[전이학습+딥러닝 서비스]_10. 폴더 내부 모든 특정 파일 삭제 기능 구현, 모든 기능을 argpase에 등록하기" },
    { "id": "RDdxueGw1rY", "title": "[전이학습+딥러닝 서비스]_09. 학습데이터를 Train/Test set으로 분할하는 기능 구현" },
    { "id": "oiUKGI8Z28k", "title": "[전이학습+딥러닝 서비스]_08. csv 또는 pickle 저장 기능을 argparse에 등록하기" },
    { "id": "8hpeplbENK8", "title": "[전이학습+딥러닝 서비스]_07. 데이터셋을 .csv 또는 pickle 파일로 저장하기" },
    { "id": "P9dw_xLxpZw", "title": "[전이학습+딥러닝 서비스]_14. (Finetune) Trainer 클래스의 load_dataset 메서드 구현 및 argparse 등록" },
    { "id": "Gby9Hfjt1DU", "title": "[전이학습+딥러닝 서비스]_13. (Finetune) 긴급 수정 ㅠㅠ - \".csv\" 데이터 파일 header(제목줄) 추가" },
    { "id": "lHActMFrWa4", "title": "[전이학습+딥러닝 서비스]_12. (Finetune) 파인튜닝에 필요한 폴더/파일 생성, 필요한 패키지 설치" },
    { "id": "iOaU--mAmf0", "title": "[전이학습+딥러닝 서비스]_15. (Finetune) whisper 모델 종류 및 디렉토리 구조를 __init__ 함수에 초기화 해주기" },
    { "id": "0ST_zq5cUWQ", "title": "[전이학습+딥러닝 서비스]_16. (Finetune) whisper tokenizer, feature extractor, processor 등록(로딩), cache 폴더 확인 하기" },
    { "id": "SGD066w8PCw", "title": "[전이학습+딥러닝 서비스]_18. (Finetune) whisper feature_extractor 적용을 위한 prepare_dataset 및 process_dataset 구현" },
    { "id": "Huj_E50U_e8", "title": "[전이학습+딥러닝 서비스]_17. (Finetune) 로딩한 whisper tokenizer의 정상 작동 확인" },
    { "id": "1CDM-fi4s3A", "title": "[전이학습+딥러닝 서비스]_20. (Finetune) whisper 학습 argument 설정, trainer 생성, 학습 수행(trainer.run) 구현" },
    { "id": "oc3ls_bKjqk", "title": "[전이학습+딥러닝 서비스]_19. (Finetune) whisper 학습 언어(language) 설정, 평가지표(evaluation metric) 등록, 사전학습 모델 등록" },
    { "id": "de49OqoS5yU", "title": "[전이학습+딥러닝 서비스]_21. (Finetune) Whisper 파인튜팅 학습 수행(실제 학습)" },
    { "id": "ZWkt_Mqbiv0", "title": "[전이학습+딥러닝 서비스]_22. (Finetune) Whisper Inference (학습 완료 모델을 이용한 추론 테스트) + 마무리 인사 ^^" },
    { "id": "M2feOKAoXTc", "title": "[OpenAI Whisper Local Live ASR]_01. (OT) Local Live ASR 구현을 위한 오리엔테이션 (Attack Plan)" },
    { "id": "cWp4vaPGeww", "title": "[OpenAI Whisper Local Live ASR]_06. VAD 및 Whisper 모델 연동, 미니 프로젝트 #2 마무리 인사" },
    { "id": "KXcZLEuxMA4", "title": "[OpenAI Whisper Local Live ASR]_05. 전이학습 모델 로딩을 위한 models/whisper.py 코딩" },
    { "id": "4NqRilfuTpA", "title": "[OpenAI Whisper Local Live ASR]_04. Entry point main.py 코딩 (argparser 포함)" },
    { "id": "DQW0cqXYa6Q", "title": "[OpenAI Whisper Local Live ASR]_03. VAD 코드 분석 및 vad.py 작성" },
    { "id": "WcDYe3rswI4", "title": "[OpenAI Whisper Local Live ASR]_02. 프로젝트 폴더구조 생성, finetuned model 복사, audio_io 구현" },
    { "id": "0tXTsIUNMOI", "title": "[OpenAI Whisper CS-based File ASR]_01. 클라이언트-서버 기반 File ASR 서비스 구현 오리엔테이션 (Attack Plan)" },
    { "id": "5ikry4jIDkA", "title": "[정보이론]_03-1. 정보 엔트로피(entropy) 개념, 표기, 연산 - 이론" },
    { "id": "03usOd5Uwa0", "title": "[정보이론]_02. 정보이론에서 '정보(information)'이란 무엇일까?" },
    { "id": "Gz1mKx5L7K8", "title": "[정보이론]_03-2. 정보 엔트로피(entropy) 개념, 표기, 연산 - 실습" },
    { "id": "EwME3JH_EaM", "title": "[정보이론]_04. 딥러닝에서의 엔트로피(entropy)" },
    { "id": "HJBsq19pcbY", "title": "[정보이론]_05-2. 엔트로피 손실(Cross Entropy Loss) 실습" },
    { "id": "t6WIGyz0tD8", "title": "[정보이론]_05-1. 엔트로피 손실 (Binary Cross Entropy, Cross Entropy) - Deep dive" },
    { "id": "6pRJnQTCoYE", "title": "[정보이론]_07. 정보 이론 시리즈를 마무리 하며 (요약, 정리, 인사말씀)" },
    { "id": "bE9dSiW6_h4", "title": "[정보이론]_06. KL 발산 (Kullback-Leibler Divergence) in Deeplearning" },
    { "id": "j1D1jY71Wjg", "title": "[미분]_01. 미분 시리즈를 시작하며, 오리엔테이션 (Orientation)" },
    { "id": "QU99KdtT81I", "title": "[미분]_05. 경사 하강법 (Gradient Descent) 알고리즘의 개념, 해석, 학습" },
    { "id": "_8chLG-JFDo", "title": "[미분]_04. 딥러닝에서 편미분 개념과 연산" },
    { "id": "wHRAvJehL20", "title": "[미분]_02. 딥러닝은 어떻게 데이터로부터 지식을 배우는가?" },
    { "id": "_cAIzjWQ3Bg", "title": "[미분]_07_02. 선형시스템에서의 편미분 (실습 with toy example)" },
    { "id": "o3IeCWtHxG4", "title": "[미분]_07_01. 선형시스템에서의 편미분 (Partial Differentiation in Linear System)" },
    { "id": "4aWZePsJ0Ro", "title": "[미분]_06. 연쇄법칙 (chain rule) 개념과 및 연산" },
    { "id": "5ds26Ntf4-0", "title": "[미분]_03. 미분의 원리 (기본 지식) - 한번은 짚고 넘어가야 할 내용" },
    { "id": "KX8C9EU4lGc", "title": "[미분]_10. 딥러닝 수학 시리즈(확률, 선형대수, 미분) 전체를 마무리하며, 감사인사 (adjourning)" },
    { "id": "dYdHdoYVzxc", "title": "[미분]_09. 활성함수 간단 소개, 기울기 소실의 근본 원인과 대책" },
    { "id": "T4Im-qIl0Xc", "title": "[미분]_08. 역전파 학습 (back-propagation) 및 Computation Graph" },
    { "id": "tv5swAHtqhk", "title": "[딥러닝 배포]_03. 배포 서버 구축 -  프런트 템플릿 작성(base.htm, main.html)" },
    { "id": "gBR3FvEIang", "title": "[딥러닝 배포]_02. 배포 서버 구축 -  폴더 구조 생성, 설정파일 작성, Main Controller (main_view), 블루프린트 등록" },
    { "id": "VQChvFGhxrE", "title": "[딥러닝 배포]_01. 배포 서버 구축 - 오리엔테이션 및 가상환경 구축" },
    { "id": "Ly31-ow14rc", "title": "[딥러닝 배포]_05. 파일첨부 부가기능(Form clear, 첨부 제외, 파일을 Form에 저장), 비동기 Ajax 통신 구현, 백엔드(서버) 파일처리" },
    { "id": "nM7DrE3okHA", "title": "[딥러닝 배포]_04. 파일첨부 기능 지원을 위한 JavaScript 코딩 (파일 추가 함수, 파일 검증 함수)" },
    { "id": "qM_pdELVXhA", "title": "[서버 모니터링]_05. 다중 접속, 다중 사용자 처리" },
    { "id": "1R5Q8gA2NMg", "title": "[서버 모니터링]_04. Progress-bar 및 결과창 동적 처리" },
    { "id": "4FoSOLBUxfk", "title": "[서버 모니터링]_03. 백엔드 코딩(run_server.py 생성, run.sh 수정, __init__.py 수정), 서버 작동 확인" },
    { "id": "jDD9191v_GA", "title": "[서버 모니터링]_02. 의존성 설치, progress-bar 코딩, 프런트 websocket 코딩" },
    { "id": "qP_Vt4tXWX0", "title": "[서버 모니터링]_01. 딥러닝 배포 서버 모니터링 필요성, 접근방법, 목표 시스템" },
    { "id": "3_6O1ErlCJs", "title": "[정보이론]_01. 오리엔테이션 - 딥러닝과 정보이론의 관계, 학습목표, 과정 소개 등" },
    { "id": "6qdZygiry_E", "title": "[선형대수]_13. 그림으로 이해하는 행렬식 (determinant)" },
    { "id": "EXMWzuZHbfo", "title": "[선형대수]_12. 행렬과 행렬을 곱한다는 의미(선형변환의 합성)" },
    { "id": "1E02Md0o-Vc", "title": "[선형대수]_11. 행렬을 이용한 선형변환(Linear Transformation)" },
    { "id": "pPIFauuiwEU", "title": "[선형대수]_14. 벡터에서 텐서로 - 텐서의 깊은 이해 (deep dive)" },
    { "id": "3uDd-xaipoU", "title": "[선형대수]_20. 선형대수를 마무리하며, 인사말 및 감사인사 (adjourning)" },
    { "id": "2vgpAgsqSEc", "title": "[선형대수]_19. 선형변환 요약, 정보 압축 및 팽창" },
    { "id": "ORSP-Rd2NcU", "title": "[선형대수]_18. 행렬에서의 랭크(Rank in Matrix)" },
    { "id": "uAVlPBC8TGE", "title": "[선형대수]_17. 차원 축소 및 확장 (dimension reduction & expansion)" },
    { "id": "FDEIHuBanwM", "title": "[선형대수]_16. 고윳값(eigenvalue)과 고유벡터(eigenvector) 이해하기" },
    { "id": "JQ1k8axkbFY", "title": "[선형대수]_15. 선형 시스템(공간)간의 해석 (Linear Empathy) - 상대방의 공간을 어떻게 해석하나요?" },
    { "id": "MKzejgqrW6Q", "title": "[선형대수]_05. 벡터 소개 (역사, 정의 및 표현법, 종류, 기저, Norm)" },
    { "id": "VophYxpve0k", "title": "[선형대수]_07. 벡터의 곱셈 (내적, Cosine Similarity, Cross곱)" },
    { "id": "HTXay7LuSlY", "title": "[선형대수]_09. 벡터의 선형결합(Linear Combination) 및 생성(Span) 좀 더 깊게 이해하기" },
    { "id": "6EjSnqXGwHQ", "title": "[선형대수]_08. 벡터 공간 (vector space) 및  부분 공간 (vector subspace)" },
    { "id": "unImvUEv9nM", "title": "[선형대수]_11. 행렬을 이용한 선형변환(Linear Transformation)" },
    { "id": "dlFRj45ckXE", "title": "[선형대수]_10. 선형변환(Linear Transformation), 벡터와 행렬의 만남" },
    { "id": "Si2QxZEz8Po", "title": "[선형대수]_01. 딥러닝에서의 선형대수! 오리엔테이션 (동기부여)" },
    { "id": "ToWPEh1neCY", "title": "[선형대수]_02. Matrix(행렬) 역사, 표현법, 행렬의 종류" },
    { "id": "rfeEx1saFVE", "title": "[선형대수]_04. Determinant(행렬식), Inverse Matrix(역행렬) 깊게 이해하기" },
    { "id": "vzNRLY_hLlM", "title": "[Probability]_09.  Maximum Likelihood Estimation (MLE) 완벽히 파헤치기 (deep dive)!" },
    { "id": "H342QehYSqo", "title": "[Probability]_10. Maximum A Posterior (MAP) 완벽히 파헤치기 (deep dive)!" },
    { "id": "126JfX_kJTU", "title": "[Probability]_11.  Bayesian Neural Networks 깊은 이해 (Bayesian Inference)" },
    { "id": "eC5Hj5TQhhI", "title": "[DB 연동] 아마존 클라우드(EC2)에 설치된 MySQL과 HeidiSQL 연동" },
    { "id": "Kmw1pCsAqfM", "title": "[Probability]_08-1. Bayesian theorem_Bayesian vs. Frequentist" },
    { "id": "7nyj0DvUluI", "title": "[Probability]_08-2-2. Bayes theorem_예제 시뮬레이션(파이썬)" },
    { "id": "xdMor6957E0", "title": "[Probability]_08-2-1. Bayes theorem_예제 풀이(당구공 굴리기)" },
    { "id": "YvWqPQhliaI", "title": "[Probability]_08-3. Bayes theorem 딥러닝 적용하여 해석하기" },
    { "id": "nw_tVBCw0Z8", "title": "[Probability]_06. 샘플링 표현에 대한 이해와 몬테 카를로 근사" }, 
    { "id": "k6xog4ZNnT0", "title": "[Probability]_07-2. Stochastic 실습 및 분석" },
    { "id": "LBT41oKsHWg", "title": "[Probability]_07-1. Stochastic Approach (확률적 접근법)" },
    { "id": "DEQhCJ0nav4", "title": "[Probability]_07-4. Stochastic Gradient Descent에 왜 &quot;Stochastic&quot;라는 단어가 붙은 건가? 미니배치에서 Stochastic 의미는?" },
    { "id": "7XJ5wA8rBDg", "title": "BERT_03_Democracy in AI, BERT training, Tokenizers" },
    { "id": "xgYyAs6D44Y", "title": "BERT_02_Self-supervised Learning, ELMO, Shadow of Big Models" },
    { "id": "iYKN10na_Y0", "title": "BERT_01_Encoder Model, Pre train, Transfer Learning" },
    { "id": "iTxTGBOhzCA", "title": "[Probability]_01.  Random Variables (확률변수)... 이게 뭔가요?" },
    { "id": "nvHyIScyQxs", "title": "[Probability]_02. Expected Value (기댓값)... 이게 뭔가요?" },
    { "id": "I9UCdp9ucQQ", "title": "01  Web Server, Web Application Server 개념 잡기" }
  ]
}