{
  "channel": {
    "id": "Tunadorable",
    "name": "Tunadorable",
    "profile": "https://yt3.googleusercontent.com/RYdiEw_tpkb48a5HPi7gTBDpQw0fl3347FmcFGtAlBjD6i_0V1uFHX0a4y4NAbSlXcwt4vk=s160-c-k-c0x00ffffff-no-rj",
    "banner": "https://yt3.googleusercontent.com/yOhhMwtCz4mgbon6RGjrb-E1iGIcIVl235eYW8HoZH9lMQK5ZIjDNkSoNKhcgZVglcsu_WPNHA=w2560-fcrop64=1,00005a57ffffa5a8-k-c0xffffffff-no-nd-rj"
  },
  "videos": [
    { "id": "2MJoErs1BuM", "title": "Working Livestream Nov 25, 2024" },
    { "id": "Fn4w2r68jNc", "title": "Live-solving LeetCode #345 - Reverse Vowels of a String" },
    { "id": "DPU--0774NY", "title": "Live-solving LeetCode #605 - Can Place Flowers" },
    { "id": "ABpxgsLOuVk", "title": "Live-solving LeetCode #151 - Reverse words in a string" },
    { "id": "IC72FbYcGQA", "title": "Live-solving LeetCode #1071 - Greatest common divisor of strings" },
    { "id": "hoPQ2Hi39hA", "title": "Live-solving LeetCode #1431 - Kids with the greatest number of candies" },
    { "id": "BMjaTqkBauI", "title": "Live-solving LeetCode #1768 - Merge strings alternately" },
    { "id": "goWFxDTc-ic", "title": "Live-solving LeetCode #11 - Container with most water" },
    { "id": "nOSx6T21Si0", "title": "Live-solving LeetCode #392 - Is subsequence" },
    { "id": "qbZRIcRmS-M", "title": "Live-solving LeetCode #283 - Move zeroes" },
    { "id": "cJ6Ezz7WuXI", "title": "Live-solving LeetCode #1456 - Maximum number of vowels in a substring of given length" },
    { "id": "cJ6Ezz7WuXI", "title": "Live-solving LeetCode #1456 - Maximum number of vowels in a substring of given length" },
    { "id": "0IDk0-IjvwI", "title": "Live-solving LeetCode #334 - Increasing triplet subsequence" },
    { "id": "JHTVJz03H3s", "title": "Live-solving LeetCode #1679 - Max number of k-sum pairs" },
    { "id": "LPfsTFcFqU4", "title": "Coding a single neuron w/ backprop in numpy | Deep-ML Code Challenges #25" },
    { "id": "s5XXYa5aeQU", "title": "Normalizing GPT on the unit-hypersphere (WITH CODE)" },
    { "id": "W7ze7dPsWyU", "title": "Theoretical physics of next token prediction in LLMs" },
    { "id": "qR56cyMdDXg", "title": "Every attention head explained" },
    { "id": "P9vpKCIbvdE", "title": "Skimming hella AI paper abstracts - Nov 5, 2024" },
    { "id": "UZcrWWL4Xk0", "title": "Bulk Skimming New AI Paper Abstracts - Sept 27, 2024" },
    { "id": "Is8I_BbsNbE", "title": "Working Livestream Oct 1, 2024" },
    { "id": "TwUF1AngZm8", "title": "Rambling about GPT architecture edit ideas" },
    { "id": "XrFm6bUDsD8", "title": "Bulk Skimming AI Paper Abstracts - Oct 9, 2024" },
    { "id": "65cLWll-7NA", "title": "Bulk Skimming AI Paper Abstracts - Oct 13, 2024" },
    { "id": "NjjV6lVgi8Q", "title": "Solving Leetcode #6 in Python (Zigzag Conversion)" },
    { "id": "lnmLwpk2FlE", "title": "FASTER than Flash Attention?!?!?! (Guest Lecturer)" },
    { "id": "K98yS4qHsFQ", "title": "How many unique paths through a grid? - LeetCode #6" },
    { "id": "RRXL4xoHg9Y", "title": "Multiple ways to calculate the fibonacci sequence - LeetCode #509" },
    { "id": "YJEBc7h2qgU", "title": "Did Meta just figure out o1-preview's secret?!?! (Guest Lecturer)" },
    { "id": "0GIGiE06ZoU", "title": "Simple changes can MASSIVELY improve transformers" },
    { "id": "YQLksOxetIE", "title": "2024.9.1 Livestream: Code w/ me - automation scripts for post-livestream video editing" },
    { "id": "mwJXKENI7HI", "title": "purposely \"pre-caching\" features or inadvertently leaving \"breadcrumbs\" for future timesteps?" },
    { "id": "b6H15EjVsUU", "title": "If early layers don't need tons of experts, can we save compute?" },
    { "id": "3o3CG6wbwm8", "title": "Models inside models inside models" },
    { "id": "5fOVGxDUuEo", "title": "Come record paper breakdown videos with me (livestream 2024.9.5)" },
    { "id": "UIIvNL_XJE8", "title": "Hate video editing? Check out my automatic video-editing suite" },
    { "id": "xR-CxiCkzsE", "title": "Why is AI so bad at multiplication?" },
    { "id": "g4VpfWNelI4", "title": "Does AI have any chance predicting chaotic systems?" },
    { "id": "l1kWyp_Egtc", "title": "Record paper breakdown videos with me (livestream 2024.9.9)" },
    { "id": "6VE6Fc1zjkk", "title": "Autoregressive decoding of sentence vectors as opposed to tokens" },
    { "id": "xHhSkq_ryWo", "title": "Bulk skimming AI paper abstracts - Sept 13, 2024" },
    { "id": "z7d0_dLTtLw", "title": "auto-regressive decoders \"think ahead\" with embedding diffusion" },
    { "id": "1C2vtgKEbcQ", "title": "Bulk skimming this week's AI papers - Sept 20, 2024" },
    { "id": "EOAT1qFQ7g4", "title": "Negative feedback control to prevent adversarial attacks" },
    { "id": "Dij_3hwpMx8", "title": "Turns out LLMs don't memorize that much" },
    { "id": "XczxSi2kHfo", "title": "MoE-Level Performance Without The Added Computation" },
    { "id": "phQYdGyPbdA", "title": "Evolutionary Optimization of Model Merging Recipes" },
    { "id": "cXOrGVk1y20", "title": "Exponentially Faster Language Modeling" },
    { "id": "kyVXA9Tgk_Y", "title": "Effect of Warm Restarts on Stochastic Gradient Descent" },
    { "id": "Q2RKLwDzCpc", "title": "Mixture of Sparse Attention for Automatic LLM Compression" },
    { "id": "pBCbWD3LYE4", "title": "Bulk Skimming Hella New AI Paper Abstracts - Aug 2, 2024" },
    { "id": "8wLG3TIcCXk", "title": "Multi-Head Mixture-of-Experts" },
    { "id": "paMM9BgkjOc", "title": "Can LLMs Learn by Teaching Other LLMs?" },
    { "id": "wbaBLCSApiA", "title": "Goldfish Loss for Mitigating Memorization in LLMs" },
    { "id": "r3jTe6AGb_E", "title": "What would it mean for an AI to \"understand\"?" },
    { "id": "diDlged7XZU", "title": "Hella New AI Papers - Aug 9, 2024" },
    { "id": "ZbCqBUamzug", "title": "Trade-off between world modeling (predicting) vs agent modeling (acting)" },
    { "id": "gI5qDjfb1Lg", "title": "What happens when you take MoE scaling laws seriously?" },
    { "id": "CG9StTrrGh4", "title": "Can concatenated small networks compete with large ones?" },
    { "id": "nGdtmC2Vyko", "title": "Are our perceptual systems structured to view the world truthfully?" },
    { "id": "2XHTqwvysog", "title": "Hella Brand New AI Paper Abstracts - Aug 18, 2024" },
    { "id": "YNQKq1YfBAI", "title": "The END of RAG? Episodic memory for infinite context length" },
    { "id": "y0o8iK6Qhv8", "title": "What's the difference between 'Inside' OOD and 'Outside' OOD?" },
    { "id": "uE_ChDHr5IM", "title": "MaskMoE: Forcing rare tokens to only use one expert" },
    { "id": "r3gAdgMIIY4", "title": "Messing with tokenization of the prompt leads to superior reasoning" },
    { "id": "WGhcxQeOGbE", "title": "Making some embedding vectors functions of each other" },
    { "id": "TOo7WE1oSJU", "title": "A new way to compare high dimensional vectors" },
    { "id": "jXpu13OeClI", "title": "A casual intro to recommendation models" },
    { "id": "yvHZ0nk8O5I", "title": "The hackiest way of making AI models self-aware" },
    { "id": "8XN2sQ7Xfn8", "title": "Some training tokens are more valuable than others" },
    { "id": "yZCi_P28RPA", "title": "Diffusion Models can Compose Images and Sounds on a Single Canvas" },
    { "id": "-i8rqo32aIM", "title": "An Exactly Solvable Model for Emergence and Scaling Laws" },
    { "id": "FoAGwdQUALM", "title": "Exploring Learning Dynamics in Concept Space" },
    { "id": "wosJpnUpIkQ", "title": "The Illusion of State in State-Space Models (like Mamba)" },
    { "id": "kUgHqRYpr5A", "title": "quadratic vs sub-quadratic architectures. fyi the human brain is sub-quadratic #ai #transformer" },
    { "id": "nyeJ8h_mMZI", "title": "Hella Brand New AI Papers - July 5, 2024" },
    { "id": "TA6kdkj2gGo", "title": "LASER: Improving LLMs with Layer-Selective Rank Reduction" },
    { "id": "KOKvSQQJYy4", "title": "Underlying Mechanisms Behind Learning Rate Warmup's Success" },
    { "id": "vlJVAHjjNtA", "title": "Better & Faster Large Language Models via Multi-token Prediction" },
    { "id": "QxD5yDzgSoE", "title": "MoE LLMs with Dense Training for Better Performance" },
    { "id": "fCXS_wo-pxo", "title": "Transformers Represent Belief State Geometry in their Residual Stream" },
    { "id": "OHHindde-h0", "title": "Cultural Accumulation in Reinforcement Learning" },
    { "id": "nu9lBnyRjos", "title": "SpaceByte: Deleting Tokenization from Large Language Modeling" },
    { "id": "JVDCRoxV6sM", "title": "The Structured Task Hypothesis" },
    { "id": "tFcz-aTBqG0", "title": "parallel processes in multi-hop LLM reasoning" },
    { "id": "B6YxQrj0Rsk", "title": "Information over-squashing in language tasks" },
    { "id": "Ur-sebi0CC8", "title": "Open-Endedness is Essential for Artificial Superhuman Intelligence" },
    { "id": "b5zUz6mn0kw", "title": "Hidden Pitfalls of Cosine Similarity Loss" },
    { "id": "cS16XnrKJjo", "title": "Let's Plug LLMs Into fMRI Scanners" },
    { "id": "dh_am72ykAQ", "title": "Retrieval Heads Mechanistically Explain Long-Context Factuality" },
    { "id": "SXvpKLiqRxM", "title": "Shorter Sequence Lengths Using Matryoshka Models" },
    { "id": "nGNdlPOWHHc", "title": "have benchmarks been the problem the whole time?!?" },
    { "id": "__xQw60y200", "title": "Accelerated Training by Amplifying Slow Gradients" },
    { "id": "F9sfAf1D3VM", "title": "Omni-modal Pretraining at Scale" },
    { "id": "gMUo_kUxPMg", "title": "Generative Models Can Outperform The Experts That Train Them" },
    { "id": "1p0DuJ13RG4", "title": "fractal trainability boundaries can arise from non-convexity" },
    { "id": "JsHV1C0rKTE", "title": "Which Tokens You Predict Underlie the Reversal Curse and More" }
  ],
  "playlists": [

  ]
}