{
  "channel": {
    "id": "vesslai",
    "name": "VESSL AI",
    "profile": "https://yt3.googleusercontent.com/IqHCDoUA8FOj4XnDPgbyCAbkaQgEk0_Q3sd516X3sChBYzjiOXodEHd6UfHqb5x9iG__mfrN=s160-c-k-c0x00ffffff-no-rj",
    "banner": "https://yt3.googleusercontent.com/ZxgO354Uo2rWPw-IyM5OO_fdnbyKJYlx4j93YJXKOWuqPrxfpGQXR-DcLaOWftVh1qu6pjQ7Kg=w1138-fcrop64=1,00005a57ffffa5a8-k-c0xffffffff-no-nd-rj"
  },
  "videos": [
    { "id": "HQF-91oE2NE", "title": "[VESSL AI] How to Get Started with VESSL: Quick Onboarding Tutorial" },
    { "id": "d2-eax9kdQ8", "title": "[VESSL AI] ScatterLab, a generative AI startup with 1.3 million users - VESSL Customer Story" },
    { "id": "mANtsFS_g6U", "title": "Introduction to VESSL AI | MLOps Platform" },
    { "id": "PiEvAtMuW7c", "title": "[MLOps Now] Enhancing AI Workflows with Custom LLM Agents — YI XIAO, Frontend Developer, Dify" },
    { "id": "iZEJBOEdMEQ", "title": "[MLOps Now] 원티드x네이버클라우드 프롬프톤 우승자의 LLMOps 개선기 — 고준서, ML Engineer, 강남언니" },
    { "id": "3nGGmd5gp-M", "title": "[MLOps Now] AI Agents에서 AGI까지 — 안재만(Jaeman An), Co-founder & CEO, VESSL AI" },
    { "id": "0b7wsKopmzQ", "title": "[MLOps Now] 한국어 RAG, 어떻게 평가하고 최적화를 해야 잘했다고 소문이 날까? — 김동규, Co-founder, AutoRAG" },
    { "id": "sgluQ34VOc4", "title": "[MLOps Now] 당신의 LLM workload를 위한 최적의 serving configuration 찾기 — 김형준, CEO, SqueezeBits" },
    { "id": "eBaVP-7Db3M", "title": "🚀 [BETA] VESSL LLM Chatbot Builder: Simplify AI with Our Enterprise-Grade Platform" },
    { "id": "3H_SGpyhfco", "title": "Easier AI Agent with Snowflake Cortex AI & VESSL Pipleline" },
    { "id": "rsh8n-EFTRY", "title": "VESSL Run & Hub 사용법" },
    { "id": "nfatOe3ZHzU", "title": "Tracking 기능을 통한 Custom Metric 차트 생성" },
    { "id": "FlNWzsg2H08", "title": "VESSL Cluster 정의 및 대시보드 활용법" },
    { "id": "ss6bxLb4KY8", "title": "[MLOps 플랫폼 VESSL 온보딩 가이드] VESSL Service 사용법" },
    { "id": "-vtQQdthrCs", "title": "[MLOps 플랫폼 VESSL 온보딩 가이드] VESSL Serverless 사용법" },
    { "id": "bb_nZ3_HrEE", "title": "[VESSL AI 가이드] 인프라 걱정 없이 AI 모델을 Serverless 서버리스 모드로 배포하기" },
    { "id": "k_Ix4uuh6IM", "title": "[VESSL AI] How to Use Serverless Mode for Machine Learning Models Guide" },
    { "id": "MAVZBkfboiE", "title": "MLOps Now — 처음부터 다시 LLM 어플리케이션 & AI Agent를 개발한다면? — ​​허훈, Tech Lead, Liner (라이너 개발 세션)" },
    { "id": "qDi0_6lWqfQ", "title": "MLOps Now Meetup — Building AI-native applications — ​Bob van Luijt, CEO, Weaviate" },
    { "id": "8bqWQ7a8028", "title": "MLOps Now — LLMOps에서 AGI까지 — 산업별 2024년 최신 사례 — ​안재만 CEO, VESSL AI" },
    { "id": "B0uTZlnrMuA", "title": "[VESSL AI Demo] Running a Face-to-Sticker Model on VESSL Hub (ENG)" },
    { "id": "ave89mMytc8", "title": "MLOps Now —  AI 연구를 위한 GPU Platform 기술  — ​​하승훈, 삼성 SDS, 컴퓨팅시스템연구Lab장 개발 세션" },
    { "id": "SqmSeSFWbSQ", "title": "MLOps Now July Complete Session - LLM in Production & AI Agent (by VESSL AI & Weaviate)" },
    { "id": "sNIUywfmiLo", "title": "🚀 [BETA] VESSL LLM Chatbot Builder: Simplify AI with Our Enterprise-Grade Platform" },
    { "id": "A0oXPJxesms", "title": "[VESSL AI 서비스 데모] #9. VESSL Pipeline 온보딩 가이드" },
    { "id": "pqMdt4ZAv5Y", "title": "MLOps Now Sep: Building context-augmented LLMs with RAG & Vector DB - Roie Schwaber-Cohen, Pinecone" },
    { "id": "pTYn2daLib0", "title": "MLOps Now Sep: Custom LLMs: Build, Deploy & Automate with RAG and Fine-Tuning -​​Jaeman An, VESSL AI" },
    { "id": "usmI4PS4N28", "title": "High-Performance LLMs: Serverless Deployment across Accelerators, GPUs, CPUs -​​ ​​Yann Leger, Koyeb" },
    { "id": "bi70tPbk1LU", "title": "MLOps Now Sep: Evaluating LLM Apps  -​​ ​​Anupam Datta, Principal Research Scientist, Snowflake" },
    { "id": "eAX8bvuwoxQ", "title": "MLOps Now Sep: Multi-agent Systems in Production -​​ ​​Laurie Voss, Developer Relations, LIamaIndex" },
    { "id": "J0Pd_NQx8sc", "title": "VESSL Workspace 사용법 및 Organization 정의" },
    { "id": "6vfPlVqBFMU", "title": "MLOps Now — Deploying LLM : Build, serve, and deploy custom private LLMs — 전지환, CTO VESSLAI (베슬에이아이)" },
    { "id": "-UynCEZEAQ0", "title": "MLOps Now — Deploying LLM : Beyond completion models to systematic Innovation — 박성호, MLE, 뤼튼테크놀로지스" },
    { "id": "xvIL29UYKFg", "title": "MLOps Now — Deploying LLM : 한국어 LLM 개발기, KoSOLAR 부터 EEVE 까지— 김승덕, Innovate Beyond 실장, 야놀자" },
    { "id": "rvMXd00CAVc", "title": "MLOps Now May — Complete Session - Custom LLM in Production (by VESSL AI & Pinecone)" },
    { "id": "J6_ReznVkzk", "title": "MLOps Now — Advancing Vector Search for LLM in Production — ​고석현, CEO, Sionic AI" },
    { "id": "4EY1TP4FrEE", "title": "MLOps Now — 쉽고 빠르게 커스텀 LLM을 파인튜닝, 배포하는 방법 — 안재만, CEO, VESSL AI" },
    { "id": "_3KYWn0FdRM", "title": "[VESSL AI 서비스 데모] #8. VESSL Serve로 Production에 배포 방법" },
    { "id": "x4kLPbWqzUo", "title": "[VESSL AI Demo] How to Deploy to Production with VESSL Serve (ENG)" },
    { "id": "YotXk7zL3oA", "title": "MLOps Now SF : Evaluation and observability stack for LLMs​ —Atin Sanyal, Galileo, LLM in production" },
    { "id": "CnURXmL56oE", "title": "MLOps Now SF : Context-augmented LLMs with RAG & Vector DB — ​Bob van Luijt, CEO, Weaviate" },
    { "id": "tQRVp-AO5FQ", "title": "MLOps Now SF : Custom LLMs—smarter, faster, and cheaper ​— Ryoo Intae, VESSL AI (LLMs in Production)" },
    { "id": "KXaRE_9eo6A", "title": "MLOps Now SF : Infrastructure challenges of LLMs​ — Jackie Poon, Samsung SDS Research" }
  ],
  "playlists": [

  ]
}