{
  "channel": {
    "id": "aipapersacademy",
    "name": "AI Papers Academy",
    "profile": "https://yt3.googleusercontent.com/FEtBvhtkQIiXklBtO8UU57GsC5ezDiWMyRnoYqNs4o04OFpUvBZWApLV8VJXXQ-IUxSBIf6w6A=s176-c-k-c0x00ffffff-no-rj",
    "banner": "https://yt3.googleusercontent.com/uitDlUnlXNXeMwUqnroXePbD6aWnCtRBjQiTjxXUlpextHgxe2NyyqIFAmIb4OsK4Q6wJdqF=w1060-fcrop64=1,00005a57ffffa5a8-k-c0xffffffff-no-nd-rj"
  },
  "videos": [
    { "id": "DimD-eX0DW8", "title": "SWE-RL by Meta â€” Reinforcement Learning for Software Engineering LLMs" },
    { "id": "RQ-0LkpUNro", "title": "DeepSeek Janus-Pro: DeepSeek's Revolution in Multimodal AI?" },
    { "id": "S4QP4AR-C-Y", "title": "s1: Simple Test-Time Scaling - Can 1k Samples Rival o1-Preview?" },
    { "id": "HkL7Wq0Uzh4", "title": "CoCoMix by Meta AI - The Future of LLMs Pretraining?" },
    { "id": "TxeR1D8T87M", "title": "Large Language Diffusion Models - The Era Of Diffusion LLMs?" },
    { "id": "TwLiNTYvpPo", "title": "Large Concept Models (LCMs) by Meta: The Era of AI After LLMs?" },
    { "id": "dQxjM1ZwiNw", "title": "Titans by Google: The Era of AI After Transformers?" },
    { "id": "DCqqCLlsIBU", "title": "DeepSeek-R1 Paper Explained - A New RL LLMs Era in AI?" },
    { "id": "HuEgzyNOg7Y", "title": "Byte Latent Transformer (BLT) by Meta AI - A Tokenizer-free LLM" },
    { "id": "Ak0vkBKOz0U", "title": "Generative Reward Models: Merging the Power of RLHF and RLAIF for Smarter AI" },
    { "id": "4weeoIjWIXI", "title": "Tokenformer: The Next Generation of Transformers?" },
    { "id": "eZNazN-1lPo", "title": "LLaMA-Mesh by Nvidia: LLM for 3D Mesh Generation" },
    { "id": "9EdYwMMABnA", "title": "Hymba by NVIDIA: A Hybrid Mamba-Transformer SOTA Small LM" },
    { "id": "kb6eH0zCnl8", "title": "Introduction to Mixture-of-Experts (MoE)" },
    { "id": "rJAndyAbErc", "title": "Mixture of Nested Experts: Adaptive Processing of Visual Tokens | AI Paper Explained" },
    { "id": "JODc9ku5djA", "title": "Writing in the Margins: Better LLM Inference Pattern for Long Context Retrieval" },
    { "id": "GK2kritsbbM", "title": "ReFT: Representation Finetuning for Language Models | AI Paper Explained" },
    { "id": "EyA3_gYzhmY", "title": "CLLMs: Consistency Large Language Models | AI Paper Explained" },
    { "id": "ENykjLzRpoI", "title": "Arithmetic Transformers with Abacus Positional Embeddings | AI Paper Explained" },
    { "id": "ZpxQec_3t38", "title": "The Era of 1-bit LLMs by Microsoft | AI Paper Explained" },
    { "id": "lmPdcTsy9rM", "title": "Stealing Part of a Production Language Model | AI Paper Explained" }
  ]
}